experiment_name:                    test                      # Name of the experiment.
use_gpu:                            True                      # Use a gpu if one is available.
seed:                               1                         # Random seed to ensure reproducibility.
relative_data_path:                 ../data/                  # Path to the dataset directory.

model:
  approximate_posterior:            gaussian                  # Family of functions to use for approximate posterior (q_\phi(z | x)).
  initialisation:                   xavier_uniform
  initialisation_std:               0.1                       # Standard deviation of the weight and bias initialization.
  nonlinearity:                     elu                       # Activation function (e.g., sigmoid, elu, ReLU, tanh, etc.).
  input_dimension:                  784                       # Number of input (and output) dimensions.
  latent_dimension:                 50                        # Number of latent dimensions.

  encoder:
    network_type:                     feedforward             # Type of encoder network (i.e., feedforward or convolutional).
    hidden_dimensions:                [200, 200]              # Layer dimensions in the encoder network (excluding the input dimensions and final latent dimensions).

  decoder:
    network_type:                     feedbackward            # Type of decoder network (i.e. feedforward or (de)convolutional)
    hidden_dimensions:                [200, 200]              # Layer dimensions in the decoder network (excluding output dimensions).

training:
  learning_rate:                    0.0001                    # Learning rate for gradient descent.
  optimiser:                        
    type:                           adam                      # Gradient descent optimizer (e.g., ADAM, Adagrad, SGD, etc.).
    params:                         [0.9, 0.999, 0.0001]
  dataset:                          binarised_mnist           # Dataset to use for training and testing (e.g., mnist, binarised_mnist, fashion_mnist, or cifar).
  batch_size:                       100                       # Size of the training batches.
  loss_function:
  num_epochs:                       300                       # Number of training epochs.
  warm_up_program:                  400                       # Limit of linear entropy-annealing (= warm-up) program (set to 0 if no entropy annealing wanted). 400 is the default

testing:
  test_frequency:                   100                       # Number of training steps between tests.
  visualise:                        True                      # Capture the output image of the test.

estimator:
  type: "none"                                                # Type of log-likelihood estimator (e.g., None, IWAE)
  iwae:
    samples: 20                                               # Number of samples to use in the IWAE estimate.
